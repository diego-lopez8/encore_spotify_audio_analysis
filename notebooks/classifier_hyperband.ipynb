{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune.integration.keras import TuneReportCallback\n",
    "from ray.tune.schedulers import HyperBandScheduler\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import psutil\n",
    "from tensorflow import keras \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df = pd.read_csv(\"complete_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>sub-emotion</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.722</td>\n",
       "      <td>0.7190</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-8.565</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0540</td>\n",
       "      <td>0.02220</td>\n",
       "      <td>0.223000</td>\n",
       "      <td>0.1100</td>\n",
       "      <td>0.955</td>\n",
       "      <td>148.039</td>\n",
       "      <td>187239.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Happy</td>\n",
       "      <td>Wonder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.378</td>\n",
       "      <td>0.3150</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-6.743</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0304</td>\n",
       "      <td>0.80200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5050</td>\n",
       "      <td>0.521</td>\n",
       "      <td>74.663</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Happy</td>\n",
       "      <td>Wonder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.291</td>\n",
       "      <td>0.0462</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-22.589</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0345</td>\n",
       "      <td>0.92500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1060</td>\n",
       "      <td>0.276</td>\n",
       "      <td>171.368</td>\n",
       "      <td>152773.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Happy</td>\n",
       "      <td>Wonder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.722</td>\n",
       "      <td>0.7970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.179</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0887</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.339000</td>\n",
       "      <td>0.0989</td>\n",
       "      <td>0.273</td>\n",
       "      <td>122.025</td>\n",
       "      <td>177523.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Happy</td>\n",
       "      <td>Wonder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.651</td>\n",
       "      <td>0.7860</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-3.725</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0761</td>\n",
       "      <td>0.00350</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.1790</td>\n",
       "      <td>0.414</td>\n",
       "      <td>109.019</td>\n",
       "      <td>178421.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Happy</td>\n",
       "      <td>Wonder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.774</td>\n",
       "      <td>0.7840</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-4.549</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0351</td>\n",
       "      <td>0.19400</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.2930</td>\n",
       "      <td>0.533</td>\n",
       "      <td>127.042</td>\n",
       "      <td>177689.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Happy</td>\n",
       "      <td>Wonder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.498</td>\n",
       "      <td>0.7450</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-5.801</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.05740</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2550</td>\n",
       "      <td>0.258</td>\n",
       "      <td>125.973</td>\n",
       "      <td>177143.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Happy</td>\n",
       "      <td>Wonder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.751</td>\n",
       "      <td>0.7840</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-4.964</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1380</td>\n",
       "      <td>0.05210</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.0629</td>\n",
       "      <td>0.533</td>\n",
       "      <td>106.069</td>\n",
       "      <td>164151.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Happy</td>\n",
       "      <td>Wonder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.728</td>\n",
       "      <td>0.9470</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.220</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0828</td>\n",
       "      <td>0.01770</td>\n",
       "      <td>0.002540</td>\n",
       "      <td>0.0987</td>\n",
       "      <td>0.553</td>\n",
       "      <td>125.874</td>\n",
       "      <td>238265.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Happy</td>\n",
       "      <td>Wonder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.537</td>\n",
       "      <td>0.9640</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-2.677</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0552</td>\n",
       "      <td>0.01800</td>\n",
       "      <td>0.001380</td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.509</td>\n",
       "      <td>125.992</td>\n",
       "      <td>208254.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Happy</td>\n",
       "      <td>Wonder</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   danceability  energy   key  loudness  mode  speechiness  acousticness  \\\n",
       "0         0.722  0.7190   6.0    -8.565   0.0       0.0540       0.02220   \n",
       "1         0.378  0.3150   7.0    -6.743   1.0       0.0304       0.80200   \n",
       "2         0.291  0.0462   5.0   -22.589   1.0       0.0345       0.92500   \n",
       "3         0.722  0.7970   0.0    -5.179   1.0       0.0887       0.00448   \n",
       "4         0.651  0.7860   9.0    -3.725   1.0       0.0761       0.00350   \n",
       "5         0.774  0.7840  10.0    -4.549   1.0       0.0351       0.19400   \n",
       "6         0.498  0.7450  11.0    -5.801   0.0       0.0316       0.05740   \n",
       "7         0.751  0.7840   8.0    -4.964   1.0       0.1380       0.05210   \n",
       "8         0.728  0.9470   0.0    -4.220   0.0       0.0828       0.01770   \n",
       "9         0.537  0.9640   5.0    -2.677   0.0       0.0552       0.01800   \n",
       "\n",
       "   instrumentalness  liveness  valence    tempo  duration_ms  time_signature  \\\n",
       "0          0.223000    0.1100    0.955  148.039     187239.0             3.0   \n",
       "1          0.000000    0.5050    0.521   74.663      48000.0             4.0   \n",
       "2          0.000000    0.1060    0.276  171.368     152773.0             4.0   \n",
       "3          0.339000    0.0989    0.273  122.025     177523.0             4.0   \n",
       "4          0.000070    0.1790    0.414  109.019     178421.0             4.0   \n",
       "5          0.000011    0.2930    0.533  127.042     177689.0             4.0   \n",
       "6          0.000000    0.2550    0.258  125.973     177143.0             4.0   \n",
       "7          0.000026    0.0629    0.533  106.069     164151.0             4.0   \n",
       "8          0.002540    0.0987    0.553  125.874     238265.0             4.0   \n",
       "9          0.001380    0.1600    0.509  125.992     208254.0             4.0   \n",
       "\n",
       "  sub-emotion emotion  \n",
       "0       Happy  Wonder  \n",
       "1       Happy  Wonder  \n",
       "2       Happy  Wonder  \n",
       "3       Happy  Wonder  \n",
       "4       Happy  Wonder  \n",
       "5       Happy  Wonder  \n",
       "6       Happy  Wonder  \n",
       "7       Happy  Wonder  \n",
       "8       Happy  Wonder  \n",
       "9       Happy  Wonder  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_df_re = complete_df.iloc[:, np.r_[1:12, 17:21]]\n",
    "complete_df_re = complete_df_re.dropna()\n",
    "complete_df_re.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(complete_df_re.iloc[:, -1])\n",
    "encoded_Y = encoder.transform(complete_df_re.iloc[:, -1])\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(complete_df_re.iloc[:, :-2], dummy_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config, X_tunetrain=None, y_tunetrain=None, X_tunetest=None, y_tunetest=None):\n",
    "    model = Sequential()\n",
    "    model.add(layer=keras.layers.Input(shape=X_train.shape[1],))\n",
    "    for i in range(config['layers']):\n",
    "        model.add(Dense(config[\"units\"], activation='relu'))\n",
    "        model.add(Dropout(config['dropout']))\n",
    "        if config['batchnorm'] == \"True\": \n",
    "            model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(9, activation='softmax'))\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=keras.optimizers.Adam(lr=config['lr'], decay=1e-6), metrics=['accuracy'])\n",
    "    model.fit(X_tunetrain, y_tunetrain, batch_size=config['batch_size'], validation_data=(X_tunetest, y_tunetest), epochs=25, callbacks=[TuneReportCallback({\"mean_accuracy\": \"accuracy\"})])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "        \"batch_size\" : tune.grid_search([64,128,256, 512]),\n",
    "        \"layers\":     tune.grid_search([i for i in range(1,150,3)]),     # maximum number of layers\n",
    "        \"units\":      tune.grid_search([128, 256, 512, 1024]),\n",
    "        \"dropout\":    tune.uniform(0, 1),\n",
    "        \"lr\":          tune.uniform(0.0001, 0.1),\n",
    "        \"batchnorm\" : tune.choice([\"True\", \"False\"])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperband_scheduler = HyperBandScheduler(\n",
    "    time_attr='training_iteration',\n",
    "    metric='mean_accuracy',\n",
    "    mode='max',\n",
    "    max_t=10,\n",
    "    reduction_factor=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-16 00:38:35,361\tINFO services.py:1456 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
      "2022-05-16 00:38:36,544\tWARNING worker.py:523 -- `ray.get_gpu_ids()` will always return the empty list when called from the driver. This is because Ray does not manage GPU allocations to the driver process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "ray.init(num_gpus=1)\n",
    "print(ray.get_gpu_ids())\n",
    "# prints []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-05-16 00:53:58 (running for 00:15:20.92)<br>Memory usage on this node: 10.4/16.0 GiB<br>Using HyperBand: num_stopped=4 total_brackets=11\n",
       "Round #0:\n",
       "  Bracket(Max Size (n)=3, Milestone (r)=10, completed=100.0%): {TERMINATED: 3} \n",
       "  Bracket(Max Size (n)=2, Milestone (r)=8, completed=42.9%): {PENDING: 2, TERMINATED: 4} \n",
       "Round #1:\n",
       "  Bracket(Max Size (n)=3, Milestone (r)=10, completed=93.3%): {PAUSED: 1, RUNNING: 2} \n",
       "  Bracket(Max Size (n)=6, Milestone (r)=2, completed=28.6%): {PAUSED: 4, RUNNING: 2} \n",
       "Round #2:\n",
       "  Bracket(Max Size (n)=3, Milestone (r)=10, completed=0.0%): {PENDING: 3} \n",
       "  Bracket(Max Size (n)=6, Milestone (r)=2, completed=0.0%): {PENDING: 6} \n",
       "Round #3:\n",
       "  Bracket(Max Size (n)=3, Milestone (r)=10, completed=0.0%): {PENDING: 3} \n",
       "  Bracket(Max Size (n)=6, Milestone (r)=2, completed=0.0%): {PENDING: 2} <br>Resources requested: 8.0/8 CPUs, 0/1 GPUs, 0.0/7.63 GiB heap, 0.0/2.0 GiB objects<br>Result logdir: /Users/diego/ray_results/exp<br>Number of trials: 32/800 (5 PAUSED, 16 PENDING, 4 RUNNING, 7 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 578/1314 [============>.................] - ETA: 12s - loss: 2.1817 - accuracy: 0.1466\n",
      "580/657 [=========================>....] - ETA: 2s - loss: 2.1260 - accuracy: 0.1896\n",
      "4675/5254 [=========================>....] - ETA: 27s - loss: 2.1961 - accuracy: 0.1414\n",
      "2322/2627 [=========================>....] - ETA: 14s - loss: 2.2352 - accuracy: 0.1318\n",
      " 584/1314 [============>.................] - ETA: 12s - loss: 2.1817 - accuracy: 0.1465\n",
      "582/657 [=========================>....] - ETA: 2s - loss: 2.1259 - accuracy: 0.1897\n",
      "4676/5254 [=========================>....] - ETA: 27s - loss: 2.1961 - accuracy: 0.1414\n",
      "2323/2627 [=========================>....] - ETA: 14s - loss: 2.2352 - accuracy: 0.1318\n",
      " 590/1314 [============>.................] - ETA: 12s - loss: 2.1818 - accuracy: 0.1464\n",
      "586/657 [=========================>....] - ETA: 2s - loss: 2.1260 - accuracy: 0.1898\n",
      "4679/5254 [=========================>....] - ETA: 27s - loss: 2.1961 - accuracy: 0.1414\n",
      "2327/2627 [=========================>....] - ETA: 14s - loss: 2.2352 - accuracy: 0.1318\n",
      " 596/1314 [============>.................] - ETA: 12s - loss: 2.1818 - accuracy: 0.1464\n",
      "588/657 [=========================>....] - ETA: 2s - loss: 2.1260 - accuracy: 0.1897\n",
      "4680/5254 [=========================>....] - ETA: 27s - loss: 2.1961 - accuracy: 0.1414\n",
      "2328/2627 [=========================>....] - ETA: 14s - loss: 2.2352 - accuracy: 0.1318\n",
      " 602/1314 [============>.................] - ETA: 12s - loss: 2.1817 - accuracy: 0.1465\n",
      "592/657 [==========================>...] - ETA: 2s - loss: 2.1259 - accuracy: 0.1897\n",
      "4683/5254 [=========================>....] - ETA: 27s - loss: 2.1961 - accuracy: 0.1414\n",
      "2330/2627 [=========================>....] - ETA: 14s - loss: 2.2353 - accuracy: 0.1318\n",
      " 608/1314 [============>.................] - ETA: 12s - loss: 2.1818 - accuracy: 0.1464\n",
      "594/657 [==========================>...] - ETA: 2s - loss: 2.1260 - accuracy: 0.1897\n",
      "4685/5254 [=========================>....] - ETA: 27s - loss: 2.1961 - accuracy: 0.1414\n",
      "2332/2627 [=========================>....] - ETA: 14s - loss: 2.2353 - accuracy: 0.1317\n",
      " 614/1314 [=============>................] - ETA: 12s - loss: 2.1817 - accuracy: 0.1465\n",
      "598/657 [==========================>...] - ETA: 1s - loss: 2.1259 - accuracy: 0.1897\n",
      "4688/5254 [=========================>....] - ETA: 26s - loss: 2.1961 - accuracy: 0.1414\n",
      "2333/2627 [=========================>....] - ETA: 14s - loss: 2.2353 - accuracy: 0.1317\n",
      " 618/1314 [=============>................] - ETA: 12s - loss: 2.1817 - accuracy: 0.1464\n",
      "602/657 [==========================>...] - ETA: 1s - loss: 2.1259 - accuracy: 0.1898\n",
      "4690/5254 [=========================>....] - ETA: 26s - loss: 2.1961 - accuracy: 0.1414\n",
      "2334/2627 [=========================>....] - ETA: 14s - loss: 2.2353 - accuracy: 0.1318\n",
      " 624/1314 [=============>................] - ETA: 12s - loss: 2.1817 - accuracy: 0.1466\n",
      "604/657 [==========================>...] - ETA: 1s - loss: 2.1259 - accuracy: 0.1898\n",
      "4691/5254 [=========================>....] - ETA: 26s - loss: 2.1961 - accuracy: 0.1414\n",
      "2335/2627 [=========================>....] - ETA: 14s - loss: 2.2353 - accuracy: 0.1317\n",
      " 630/1314 [=============>................] - ETA: 11s - loss: 2.1818 - accuracy: 0.1465\n",
      "608/657 [==========================>...] - ETA: 1s - loss: 2.1259 - accuracy: 0.1898\n",
      "4695/5254 [=========================>....] - ETA: 26s - loss: 2.1960 - accuracy: 0.1414\n",
      "2337/2627 [=========================>....] - ETA: 14s - loss: 2.2353 - accuracy: 0.1317\n",
      " 637/1314 [=============>................] - ETA: 11s - loss: 2.1818 - accuracy: 0.1465\n",
      "612/657 [==========================>...] - ETA: 1s - loss: 2.1258 - accuracy: 0.1898\n",
      "4697/5254 [=========================>....] - ETA: 26s - loss: 2.1960 - accuracy: 0.1414\n",
      "2339/2627 [=========================>....] - ETA: 14s - loss: 2.2352 - accuracy: 0.1318\n",
      " 644/1314 [=============>................] - ETA: 11s - loss: 2.1817 - accuracy: 0.1466\n",
      "614/657 [===========================>..] - ETA: 1s - loss: 2.1257 - accuracy: 0.1899\n",
      "4699/5254 [=========================>....] - ETA: 26s - loss: 2.1961 - accuracy: 0.1414\n",
      "2341/2627 [=========================>....] - ETA: 14s - loss: 2.2352 - accuracy: 0.1318\n",
      " 647/1314 [=============>................] - ETA: 11s - loss: 2.1817 - accuracy: 0.1466\n",
      "617/657 [===========================>..] - ETA: 1s - loss: 2.1257 - accuracy: 0.1900\n",
      "4702/5254 [=========================>....] - ETA: 26s - loss: 2.1961 - accuracy: 0.1414\n",
      "2343/2627 [=========================>....] - ETA: 13s - loss: 2.2352 - accuracy: 0.1318\n",
      " 654/1314 [=============>................] - ETA: 11s - loss: 2.1817 - accuracy: 0.1466\n",
      "619/657 [===========================>..] - ETA: 1s - loss: 2.1257 - accuracy: 0.1900\n",
      "4703/5254 [=========================>....] - ETA: 26s - loss: 2.1961 - accuracy: 0.1414\n",
      "2345/2627 [=========================>....] - ETA: 13s - loss: 2.2352 - accuracy: 0.1318\n",
      " 661/1314 [==============>...............] - ETA: 11s - loss: 2.1817 - accuracy: 0.1467\n",
      "622/657 [===========================>..] - ETA: 1s - loss: 2.1256 - accuracy: 0.1900\n",
      "4705/5254 [=========================>....] - ETA: 26s - loss: 2.1961 - accuracy: 0.1414\n",
      " 667/1314 [==============>...............] - ETA: 11s - loss: 2.1817 - accuracy: 0.1467\n",
      "626/657 [===========================>..] - ETA: 0s - loss: 2.1256 - accuracy: 0.1899\n",
      "4707/5254 [=========================>....] - ETA: 25s - loss: 2.1961 - accuracy: 0.1414\n",
      "2347/2627 [=========================>....] - ETA: 13s - loss: 2.2352 - accuracy: 0.1318\n",
      " 670/1314 [==============>...............] - ETA: 11s - loss: 2.1817 - accuracy: 0.1467\n",
      "628/657 [===========================>..] - ETA: 0s - loss: 2.1255 - accuracy: 0.1900\n",
      "4709/5254 [=========================>....] - ETA: 25s - loss: 2.1961 - accuracy: 0.1414\n",
      "2348/2627 [=========================>....] - ETA: 13s - loss: 2.2352 - accuracy: 0.1318\n",
      " 676/1314 [==============>...............] - ETA: 11s - loss: 2.1818 - accuracy: 0.1468\n",
      "630/657 [===========================>..] - ETA: 0s - loss: 2.1257 - accuracy: 0.1900\n",
      "4711/5254 [=========================>....] - ETA: 25s - loss: 2.1961 - accuracy: 0.1415\n",
      "2350/2627 [=========================>....] - ETA: 13s - loss: 2.2352 - accuracy: 0.1318\n",
      " 682/1314 [==============>...............] - ETA: 11s - loss: 2.1819 - accuracy: 0.1468\n",
      "634/657 [===========================>..] - ETA: 0s - loss: 2.1256 - accuracy: 0.1899\n",
      "4713/5254 [=========================>....] - ETA: 25s - loss: 2.1961 - accuracy: 0.1415\n",
      "2351/2627 [=========================>....] - ETA: 13s - loss: 2.2352 - accuracy: 0.1318\n",
      " 689/1314 [==============>...............] - ETA: 10s - loss: 2.1818 - accuracy: 0.1470\n",
      "638/657 [============================>.] - ETA: 0s - loss: 2.1255 - accuracy: 0.1900\n",
      "4715/5254 [=========================>....] - ETA: 25s - loss: 2.1961 - accuracy: 0.1415\n",
      "2354/2627 [=========================>....] - ETA: 13s - loss: 2.2352 - accuracy: 0.1318\n",
      " 696/1314 [==============>...............] - ETA: 10s - loss: 2.1818 - accuracy: 0.1470\n",
      "640/657 [============================>.] - ETA: 0s - loss: 2.1255 - accuracy: 0.1900\n",
      "4717/5254 [=========================>....] - ETA: 25s - loss: 2.1961 - accuracy: 0.1415\n",
      "2356/2627 [=========================>....] - ETA: 13s - loss: 2.2351 - accuracy: 0.1318\n"
     ]
    }
   ],
   "source": [
    "analysis = tune.run(\n",
    "    tune.with_parameters(train, X_tunetrain=X_train, y_tunetrain=y_train, X_tunetest=X_test, y_tunetest=y_test),\n",
    "    name=\"exp\",\n",
    "    config=config,\n",
    "    verbose=1,\n",
    "    resources_per_trial={\n",
    "            \"gpu\": 0,\n",
    "            \"cpu\": 2\n",
    "        },scheduler=hyperband_scheduler)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "152817971f61c4c27a9c430bd40baec0953a77c133faf52ea680e5bbf66c0efe"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
